{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import genesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg EBook of The Adventures of Sherlock Holmes\\nby Sir Arthur Conan Doyle\\n(#15 in o'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('big.txt', 'r')\n",
    "content=data.read(100)\n",
    "content.replace('\\n', \" \")\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    return words\n",
    "words = extract_words(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all unique words\n",
    "# Save unique words to a text file\n",
    "output_file_path = \"unique_words1.txt\"\n",
    "with open(output_file_path, \"w\") as file:\n",
    "    for word in words:\n",
    "        file.write(word + \"\\n\")\n",
    "\n",
    "print(f\"Unique words saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = nltk.bigrams(words)\n",
    "#print(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_bifreq = nltk.FreqDist(bigrams)\n",
    "\n",
    "#eng_bifreq.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the frequencies\n",
    "total_frequency = sum(frequency for _, frequency in eng_bifreq.most_common())\n",
    "\n",
    "# Print the result\n",
    "print(\"Total Frequency:\", total_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h ,  i in eng_bifreq.most_common():\n",
    "    probabilities.append((h, i/total_frequency)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_dict = dict(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word to check\n",
    "word_to_check = 'Project'\n",
    "\n",
    "# List of bigrams where the second element matches word_to_check\n",
    "matching_bigrams = [bigram[0] for bigram in bigram_dict if bigram[1] == word_to_check]\n",
    "\n",
    "print(f'Bigrams where the second element is \"{word_to_check}\":')\n",
    "for bigram in matching_bigrams:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word to check\n",
    "search_word = 'Project'\n",
    "\n",
    "def filtered_bigram(word_check):\n",
    "    \n",
    "    word_to_check = word_check\n",
    "    \n",
    "    # Filter the dictionary\n",
    "    filtered_bigram_dict = {bigram: frequency for bigram, frequency in bigram_dict.items() if word_to_check in bigram}\n",
    "\n",
    "    print(f'Dictionary with bigrams containing \"{word_to_check}\":')\n",
    "    \n",
    "    return filtered_bigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_bigram_dict = filtered_bigram('Project')\n",
    "print(filtered_bigram_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enchant.utils import levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(word1, word2):\n",
    "    return levenshtein(word1, word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_words():\n",
    "    data = open('unique_words.txt', 'r')\n",
    "    content=data.read(100)\n",
    "    return content.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'The', 'Adventures', 'of', 'Sherlock', 'Holmes', 'by', 'Sir', 'Arthur', 'Conan', 'Doyle', '15', 'in', 'our']\n"
     ]
    }
   ],
   "source": [
    "unique_list = get_unique_words()\n",
    "print(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_unique_words = unique_list\n",
    "def find_distance(search_word, list_of_unique_words):\n",
    "    set_distance = set()\n",
    "    for word in list_of_unique_words:\n",
    "        tup = ((word, edit_distance(search_word, word)))\n",
    "        set_distance.add(tup)\n",
    "        min_distance_word = min(set_distance, key = lambda x: x[1])[0]\n",
    "    return min_distance_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_set = find_distance('Prohecr', list_of_unique_words) # our set containing words and edit distance foor them\n",
    "print(our_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
